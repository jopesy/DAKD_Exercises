{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight vector for the whole data: \n",
      "[  2.19652084e+01   2.49905527e-02  -1.08359026e+00  -1.82563948e-01\n",
      "   1.63312698e-02  -1.87422516e+00   4.36133331e-03  -3.26457970e-03\n",
      "  -1.78811638e+01  -4.13653144e-01   9.16334413e-01   2.76197699e-01]\n",
      "1599\n",
      "6396\n",
      "Mean of Out of sample errors: \n",
      "1.07758982753e-15\n",
      "Mean of in-sample errors: \n",
      "1.07536799283e-15\n",
      "Variance of in-sample error\n",
      "0.416767167221\n",
      "Variance of out-of-sample error\n",
      "0.416767167221\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import itertools\n",
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "\n",
    "csv_path = \"winequality-red.csv\"\n",
    "data = pd.read_csv(csv_path, sep=';')\n",
    "\n",
    "\n",
    "#Select input variables as x\n",
    "x = data.iloc[0:,0:11]\n",
    "\n",
    "#Select output variable (quality) as y\n",
    "y = data.quality\n",
    "\n",
    "#Print attribute values of first sample\n",
    "#print(x.loc[0])\n",
    "\n",
    "#Print fixed acidity value of first sample\n",
    "#print(x.loc[0].get_value(0))\n",
    "\n",
    "#Quality of first sample\n",
    "#print(y.loc[0])\n",
    "\n",
    "#print(data)\n",
    "\n",
    "#Calculate coefficients using statsmodels\n",
    "#lm = smf.ols(formula='quality ~ fixed acidity + chlorides', data=data).fit()\n",
    "#print (lm.params)\n",
    "\n",
    "#Calculate coefficients to get the weight vector for the whole data\n",
    "lm = LinearRegression()\n",
    "lm.fit(x, y)\n",
    "\n",
    "#print(lm.intercept_)\n",
    "#print(lm.coef_)\n",
    "\n",
    "weightVector = np.hstack((np.array(lm.intercept_), np.array(lm.coef_)))\n",
    "print(\"Weight vector for the whole data: \")\n",
    "print (weightVector)\n",
    "\n",
    "#Split input variable values into 5 parts\n",
    "#splittedX = np.array_split(x, 5)\n",
    "\n",
    "#Split output variable values into 5 parts\n",
    "#splittedY = np.array_split(y, 5)\n",
    "\n",
    "#Print 1st part\n",
    "#print (splittedData[0])\n",
    "\n",
    "def calculateOutOfSampleErrorVectors(dataIn):\n",
    "    #Split whole data into 5 parts\n",
    "    splittedData = np.array_split(dataIn, 5)\n",
    "\n",
    "    outOfSampleErrorVector = []\n",
    "    inSampleErrorList = []\n",
    "\n",
    "    for part in splittedData:\n",
    "        splittedX = np.array(part.iloc[0:,0:11])\n",
    "        splittedY = np.array(part.quality)\n",
    "        errors = []    \n",
    "\n",
    "        for i in range(0, len(splittedY)):        \n",
    "            sampleReshaped = splittedX[i].reshape(1, -1)\n",
    "            #make the predictions for each sample\n",
    "            predictedSample = lm.predict(sampleReshaped)\n",
    "            #calculate errors for each sample by substracting the predictions from the quality value\n",
    "            error = float(splittedY[i] - predictedSample)\n",
    "            errors.append(error)\n",
    "\n",
    "        outOfSampleErrorVector.append(errors)\n",
    "        \n",
    "        #print(outOfSampleErrorVector)\n",
    "                          \n",
    "    return outOfSampleErrorVector\n",
    "        \n",
    "def calculateInSampleErrorVectors(dataIn):\n",
    "    splittedData = np.array_split(dataIn, 5)\n",
    "    \n",
    "    indexCombinations = list(itertools.combinations(range(0, len(splittedData)), 4))\n",
    "    \n",
    "    inSampleDataList = []    \n",
    "    \n",
    "    for combination in indexCombinations:\n",
    "        inSampleData = []\n",
    "        for index in combination:\n",
    "            dataInIndex = list(np.array(splittedData[index]))\n",
    "            inSampleData += dataInIndex\n",
    "        inSampleData = np.array(inSampleData)\n",
    "        inSampleDataList.append(inSampleData)\n",
    "        \n",
    "    inSampleErrorVector = []\n",
    "    \n",
    "    for dataPart in inSampleDataList:\n",
    "        splittedX = dataPart[0:,0:11]\n",
    "        splittedY = dataPart[:,11]\n",
    "        #subtract part from the whole data set\n",
    "        errors = []\n",
    "        \n",
    "        for i in range(0, len(splittedY)):        \n",
    "            sampleReshaped = splittedX[i].reshape(1, -1)\n",
    "            #make the predictions for each sample\n",
    "            predictedSample = lm.predict(sampleReshaped)\n",
    "            #calculate errors for each sample by substracting the predictions from the quality value\n",
    "            error = float(splittedY[i] - predictedSample)\n",
    "            errors.append(error)\n",
    "\n",
    "        inSampleErrorVector.append(errors)\n",
    "        \n",
    "        #print(\"*********\")\n",
    "        #print(inSampleErrorVector)\n",
    "                          \n",
    "    return inSampleErrorVector\n",
    "    \n",
    "                      \n",
    "def concatenateVectors(vectors):\n",
    "    vectorsConcatenated = []\n",
    "    for vector in vectors:\n",
    "        vectorsConcatenated += vector\n",
    "    return vectorsConcatenated\n",
    "\n",
    "def plotHistogram(concatVector, title):\n",
    "    plt.figure()\n",
    "    plt.hist(concatVector, bins=60, color=\"red\")\n",
    "    plt.title(title), plt.xlabel(\"\"), plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "              \n",
    "    \n",
    "outOfSampleErrorVector = calculateOutOfSampleErrorVectors(data)\n",
    "inSampleErrorVector = calculateInSampleErrorVectors(data)\n",
    "outOfSampleErrorVector = calculateOutOfSampleErrorVectors(data)\n",
    "inSampleErrorVector = calculateInSampleErrorVectors(data)\n",
    "concatenatedOutSample = concatenateVectors(outOfSampleErrorVector)\n",
    "concatenatedInSample = concatenateVectors(inSampleErrorVector)\n",
    "\n",
    "print(len(concatenatedOutSample))\n",
    "print(len(concatenatedInSample))\n",
    "\n",
    "plotHistogram(concatenatedOutSample, \"Out-of-sample error histogram\")\n",
    "plotHistogram(concatenatedInSample, \"In-sample error histogram\")\n",
    "\n",
    "numpyOut = np.array(concatenatedOutSample)\n",
    "meanOut = np.mean(numpyOut)\n",
    "print(\"Mean of Out of sample errors: \")\n",
    "print (meanOut)\n",
    "       \n",
    "numpyIn = np.array(concatenatedInSample)\n",
    "meanIn = np.mean(numpyIn)\n",
    "print(\"Mean of in-sample errors: \")\n",
    "print (meanIn)\n",
    "\n",
    "varIn = np.var(numpyIn)\n",
    "varOut = np.var(numpyOut)\n",
    "\n",
    "print(\"Variance of in-sample error\")\n",
    "print(varIn)\n",
    "print(\"Variance of out-of-sample error\")\n",
    "print(varOut)\n",
    "        \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
